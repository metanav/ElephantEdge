{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Import the data from Edge Impulse. You can obtain the URL from the Dashboard, right-click on the download icon next to 'Spectral features data' and 'Spectral features labels', and click **Copy link location**."
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "outputs": [],
            "execution_count": null,
            "source": [
                "import numpy as np\n",
                "import requests\n",
                "\n",
                "API_KEY = <Insert your app key>\n",
                "\n",
                "X = (requests.get('https://studio.edgeimpulse.com/v1/api/10419/training/28/x', headers={'x-api-key': API_KEY})).content\n",
                "Y = (requests.get('https://studio.edgeimpulse.com/v1/api/10419/training/28/y', headers={'x-api-key': API_KEY})).content"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Store the data in a temporary file, and load it back through Numpy."
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "outputs": [],
            "execution_count": null,
            "source": [
                "with open('x_train.npy', 'wb') as file:\n",
                "    file.write(X)\n",
                "with open('y_train.npy', 'wb') as file:\n",
                "    file.write(Y)\n",
                "X = np.load('x_train.npy')\n",
                "Y = np.load('y_train.npy')[:,0]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Define our labels and split the data up in a test and training set:"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "outputs": [],
            "execution_count": null,
            "source": [
                "import sys, os, random\n",
                "import tensorflow as tf\n",
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "import logging\n",
                "tf.get_logger().setLevel(logging.ERROR)\n",
                "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
                "\n",
                "# Set random seeds for repeatable results\n",
                "RANDOM_SEED = 3\n",
                "random.seed(RANDOM_SEED)\n",
                "np.random.seed(RANDOM_SEED)\n",
                "tf.random.set_seed(RANDOM_SEED)\n",
                "\n",
                "classes_values = [ \"grazing\", \"lying\", \"running\", \"standing\", \"walking\" ]\n",
                "classes = len(classes_values)\n",
                "\n",
                "Y = tf.keras.utils.to_categorical(Y - 1, classes)\n",
                "\n",
                "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1)\n",
                "\n",
                "input_length = X_train[0].shape[0]\n",
                "\n",
                "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
                "validation_dataset = tf.data.Dataset.from_tensor_slices((X_test, Y_test))\n",
                "\n",
                "def set_batch_size(batch_size, train_dataset, validation_dataset):\n",
                "    train_dataset = train_dataset.batch(batch_size, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
                "    validation_dataset = validation_dataset.batch(batch_size, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
                "    return train_dataset, validation_dataset\n",
                "\n",
                "callbacks = []\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Train the model:"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "outputs": [],
            "execution_count": null,
            "source": [
                "import tensorflow as tf\n",
                "from tensorflow.keras.models import Sequential\n",
                "from tensorflow.keras import activations, regularizers\n",
                "from tensorflow.keras.layers import Dense, InputLayer, BatchNormalization, Dropout, Activation\n",
                "from tensorflow.keras.optimizers import Adam\n",
                "from tensorflow.keras.optimizers.schedules import InverseTimeDecay\n",
                "\n",
                "print(input_length)\n",
                "\n",
                "# model architecture\n",
                "model = Sequential()\n",
                "# input layer\n",
                "model.add(InputLayer(input_shape=(input_length, ), name='x_input'))\n",
                "\n",
                "# hidden layer 1\n",
                "model.add(Dense(64, activity_regularizer=regularizers.l2(0.0001)))\n",
                "model.add(BatchNormalization())\n",
                "model.add(Activation(activations.relu))\n",
                "model.add(Dropout(0.1))\n",
                "\n",
                "# hidden layer 2\n",
                "model.add(Dense(64, activity_regularizer=regularizers.l2(0.0001)))\n",
                "model.add(BatchNormalization())\n",
                "model.add(Activation(activations.relu))\n",
                "model.add(Dropout(0.1))\n",
                "\n",
                "# hidden layer 3\n",
                "model.add(Dense(64, activity_regularizer=regularizers.l2(0.0001)))\n",
                "model.add(BatchNormalization())\n",
                "model.add(Activation(activations.relu))\n",
                "model.add(Dropout(0.1))\n",
                "\n",
                "# hidden layer 4\n",
                "model.add(Dense(64, activity_regularizer=regularizers.l2(0.0001)))\n",
                "model.add(BatchNormalization())\n",
                "model.add(Activation(activations.relu))\n",
                "model.add(Dropout(0.1))\n",
                "\n",
                "# hidden layer 5\n",
                "model.add(Dense(64, activity_regularizer=regularizers.l2(0.0001)))\n",
                "model.add(BatchNormalization())\n",
                "model.add(Activation(activations.relu))\n",
                "model.add(Dropout(0.1))\n",
                "\n",
                "# hidden layer 6\n",
                "model.add(Dense(64, activity_regularizer=regularizers.l2(0.0001)))\n",
                "model.add(BatchNormalization())\n",
                "model.add(Activation(activations.relu))\n",
                "model.add(Dropout(0.1))\n",
                "\n",
                "# hidden layer 7\n",
                "model.add(Dense(32, activity_regularizer=regularizers.l2(0.0001)))\n",
                "model.add(BatchNormalization())\n",
                "model.add(Activation(activations.relu))\n",
                "model.add(Dropout(0.1))\n",
                "\n",
                "# hidden layer 8\n",
                "model.add(Dense(32, activity_regularizer=regularizers.l2(0.0001)))\n",
                "model.add(BatchNormalization())\n",
                "model.add(Activation(activations.relu))\n",
                "model.add(Dropout(0.1))\n",
                "\n",
                "# hidden layer 9\n",
                "model.add(Dense(32, activity_regularizer=regularizers.l2(0.0001)))\n",
                "model.add(BatchNormalization())\n",
                "model.add(Activation(activations.relu))\n",
                "model.add(Dropout(0.1))\n",
                "\n",
                "# hidden layer 10\n",
                "model.add(Dense(32, activity_regularizer=regularizers.l2(0.0001)))\n",
                "model.add(BatchNormalization())\n",
                "model.add(Activation(activations.relu))\n",
                "model.add(Dropout(0.1))\n",
                "\n",
                "# hidden layer 11\n",
                "model.add(Dense(32, activity_regularizer=regularizers.l2(0.0001)))\n",
                "model.add(BatchNormalization())\n",
                "model.add(Activation(activations.relu))\n",
                "model.add(Dropout(0.1))\n",
                "\n",
                "# hidden layer 12\n",
                "model.add(Dense(32, activity_regularizer=regularizers.l2(0.0001)))\n",
                "model.add(BatchNormalization())\n",
                "model.add(Activation(activations.relu))\n",
                "model.add(Dropout(0.1))\n",
                "\n",
                "# output layer\n",
                "model.add(Dense(classes, activation=\"softmax\", name='y_pred'))\n",
                "\n",
                "BATCH_SIZE = 64\n",
                "\n",
                "lr_schedule = InverseTimeDecay(\n",
                "  0.001,\n",
                "  decay_steps=train_sample_count//BATCH_SIZE*10,\n",
                "  decay_rate=1,\n",
                "  staircase=False)\n",
                "\n",
                "def get_optimizer():\n",
                "  return Adam(lr_schedule)\n",
                "  \n",
                "# this controls the learning rate\n",
                "#opt = Adam(lr=0.0005, beta_1=0.9, beta_2=0.999)\n",
                "\n",
                "# this controls the batch size, or you can manipulate the tf.data.Dataset objects yourself\n",
                "\n",
                "train_dataset, validation_dataset = set_batch_size(BATCH_SIZE, train_dataset, validation_dataset)\n",
                "\n",
                "# train the neural network\n",
                "model.compile(loss='categorical_crossentropy', optimizer=get_optimizer(), metrics=['accuracy'])\n",
                "model.fit(train_dataset, epochs=55, validation_data=validation_dataset, verbose=2, callbacks=callbacks)\n"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "outputs": [],
            "execution_count": null,
            "source": [
                "# Save the model to disk\n",
                "model.save('saved_model')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.7.3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
